{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a84b9e8",
   "metadata": {
    "id": "t5yNOH5JHj0A",
    "papermill": {
     "duration": 0.010398,
     "end_time": "2024-04-26T11:55:40.037303",
     "exception": false,
     "start_time": "2024-04-26T11:55:40.026905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## no OCR version notebook\n",
    "### with data from 2022 and 2023\n",
    "at the end of this notebook, run the model you want to try out, run the seed and generate text.\n",
    "\n",
    "this model has 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc2616f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:55:40.059007Z",
     "iopub.status.busy": "2024-04-26T11:55:40.058681Z",
     "iopub.status.idle": "2024-04-26T11:56:11.730896Z",
     "shell.execute_reply": "2024-04-26T11:56:11.729148Z"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1713964644190,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "wmWS3T4IIfV5",
    "papermill": {
     "duration": 31.686071,
     "end_time": "2024-04-26T11:56:11.733576",
     "exception": false,
     "start_time": "2024-04-26T11:55:40.047505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this will download the model for the NLP you only need to do it once\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"de_dep_news_trf\")\n",
    "except:\n",
    "    !python -m spacy download de_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4dfc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy_transformers\n",
    "# from spacy import displacy\n",
    "# from spacy.lang.fr.examples import sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f18de4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:11.778948Z",
     "iopub.status.busy": "2024-04-26T11:56:11.778581Z",
     "iopub.status.idle": "2024-04-26T11:56:29.695992Z",
     "shell.execute_reply": "2024-04-26T11:56:29.694355Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1713964644675,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "AbotKWkQHj0C",
    "papermill": {
     "duration": 17.942615,
     "end_time": "2024-04-26T11:56:29.698660",
     "exception": false,
     "start_time": "2024-04-26T11:56:11.756045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# please install requirements.txt first\n",
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin, Token\n",
    "from spacy.vocab import Vocab\n",
    "import tf_keras as keras\n",
    "from tf_keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tf_keras.models import Sequential\n",
    "from tf_keras.layers import Dense, LSTM, Embedding\n",
    "from random import randint\n",
    "from tf_keras.models import load_model\n",
    "from tf_keras.preprocessing.sequence import pad_sequences\n",
    "from pickle import dump, load\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4353ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a777f6",
   "metadata": {},
   "source": [
    "prepareing a little bit more the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b16e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:29.743547Z",
     "iopub.status.busy": "2024-04-26T11:56:29.742119Z",
     "iopub.status.idle": "2024-04-26T11:56:39.608849Z",
     "shell.execute_reply": "2024-04-26T11:56:39.607490Z"
    },
    "executionInfo": {
     "elapsed": 11650,
     "status": "ok",
     "timestamp": 1713964656324,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "EOJS4SnZL_D5",
    "papermill": {
     "duration": 9.892444,
     "end_time": "2024-04-26T11:56:39.612373",
     "exception": false,
     "start_time": "2024-04-26T11:56:29.719929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\thinc\\shims\\pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# loading the extracted data\n",
    "doc_bin = DocBin().from_disk(BASE_DIR + \"/data/data_noOCR_22-23.spacy\")\n",
    "# needed for the vocab\n",
    "nlp = spacy.load(\"de_dep_news_trf\")\n",
    "\n",
    "all_docs_sents = [i.sents for i in doc_bin.get_docs(nlp.vocab)]\n",
    "all_sents = [i for j in all_docs_sents for i in j if len(i) >= 35]\n",
    "tokens = [i.text for j in all_sents for i in j if not i.pos_ in [\"X\", \"SPACE\"]]\n",
    "text = \" \".join(tokens)\n",
    "text = text.replace(\"- \", \"\")\n",
    "tokens = text.split(\" \")\n",
    "filter_symbols = [')', '(', '/', '„', '“', '–', '%', '…', ':', ';', '�', '-', '[', ']', '≤', '=', '_', '<', '•', '+', '>', '∙', '°', '*', '−', '‘', '\\uf036', '\\uf02c', '·', '∑', '\\uf06c', '\\uf04f', '\\uf028', '\\uf026', '´', 'u', '×', '&', 'µ', '’', '≈', 'τ', '≥', '\\uf03c', '\\uf035', '□', '±', 'σ', 'ω', '”', '\\uf027', '‚', '\\uf023', '\\uf037', 'ü', '∗', 'α', 'ª', '\\uf040', '\\uf03b', '√', 'γ', '\\uf02f', '\\uf033', 'δ', '«', '»', 'á', '\\uf045', '𝑐', '∫', '\\uf031', '\\uf04b', '\\uf030', '\\uf039', '\\uf029', '~', '→', '≪', '\"', '®', '\\xad', '\\uf02b', '\\uf02a']\n",
    "tokens = [i for i in tokens if not i in filter_symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92fe28ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:39.658689Z",
     "iopub.status.busy": "2024-04-26T11:56:39.658333Z",
     "iopub.status.idle": "2024-04-26T11:56:39.665191Z",
     "shell.execute_reply": "2024-04-26T11:56:39.663971Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713964656324,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "jfYG1VkTHj0C",
    "outputId": "ffe4b32b-0b16-4ad2-edd7-cd0091a475f3",
    "papermill": {
     "duration": 0.031814,
     "end_time": "2024-04-26T11:56:39.667455",
     "exception": false,
     "start_time": "2024-04-26T11:56:39.635641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd719e60",
   "metadata": {
    "id": "NvQQaYGQHj0D",
    "papermill": {
     "duration": 0.021661,
     "end_time": "2024-04-26T11:56:39.713555",
     "exception": false,
     "start_time": "2024-04-26T11:56:39.691894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#50 words --> network predict #51\n",
    "Here we will create a text sequence of 50 words, 51th will be the prediction word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3438758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:39.759913Z",
     "iopub.status.busy": "2024-04-26T11:56:39.759527Z",
     "iopub.status.idle": "2024-04-26T11:56:41.679685Z",
     "shell.execute_reply": "2024-04-26T11:56:41.678650Z"
    },
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1713964657538,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "xkSoeJruHj0D",
    "papermill": {
     "duration": 1.945774,
     "end_time": "2024-04-26T11:56:41.682428",
     "exception": false,
     "start_time": "2024-04-26T11:56:39.736654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_len = 50 + 1\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5c4bb",
   "metadata": {
    "id": "bZOAAG5IHj0E",
    "papermill": {
     "duration": 0.020471,
     "end_time": "2024-04-26T11:56:41.820614",
     "exception": false,
     "start_time": "2024-04-26T11:56:41.800143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### loading pickle fo the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42064054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:41.862726Z",
     "iopub.status.busy": "2024-04-26T11:56:41.862358Z",
     "iopub.status.idle": "2024-04-26T11:56:41.922690Z",
     "shell.execute_reply": "2024-04-26T11:56:41.921042Z"
    },
    "executionInfo": {
     "elapsed": 9889,
     "status": "ok",
     "timestamp": 1713964667424,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "IL85HsvVHj0E",
    "papermill": {
     "duration": 0.084617,
     "end_time": "2024-04-26T11:56:41.925454",
     "exception": false,
     "start_time": "2024-04-26T11:56:41.840837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(text_sequences)\n",
    "tokenizer = load(open(BASE_DIR + '/model/demo_tokenizer','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d162b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:41.970683Z",
     "iopub.status.busy": "2024-04-26T11:56:41.970245Z",
     "iopub.status.idle": "2024-04-26T11:56:50.596678Z",
     "shell.execute_reply": "2024-04-26T11:56:50.595215Z"
    },
    "executionInfo": {
     "elapsed": 6197,
     "status": "ok",
     "timestamp": 1713964673614,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "CLLfC6S3Hj0E",
    "papermill": {
     "duration": 8.651773,
     "end_time": "2024-04-26T11:56:50.599147",
     "exception": false,
     "start_time": "2024-04-26T11:56:41.947374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317eb256",
   "metadata": {
    "id": "DvdXf8L9Hj0F",
    "papermill": {
     "duration": 0.090712,
     "end_time": "2024-04-26T11:56:50.981500",
     "exception": false,
     "start_time": "2024-04-26T11:56:50.890788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Getting the size of our vocabulary, to get the unique words across the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64d66c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:51.026442Z",
     "iopub.status.busy": "2024-04-26T11:56:51.026074Z",
     "iopub.status.idle": "2024-04-26T11:56:51.032963Z",
     "shell.execute_reply": "2024-04-26T11:56:51.031664Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1713964673615,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "1MMvn9svHj0F",
    "papermill": {
     "duration": 0.032377,
     "end_time": "2024-04-26T11:56:51.034814",
     "exception": false,
     "start_time": "2024-04-26T11:56:51.002437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35743"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7100d",
   "metadata": {
    "id": "A_GdjOoyHj0F",
    "papermill": {
     "duration": 0.021186,
     "end_time": "2024-04-26T11:56:51.076730",
     "exception": false,
     "start_time": "2024-04-26T11:56:51.055544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "changing list into numpy array\n",
    "where each row in the array represents a single textfragment, with lenght of 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2427d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:51.121455Z",
     "iopub.status.busy": "2024-04-26T11:56:51.121071Z",
     "iopub.status.idle": "2024-04-26T11:56:52.231105Z",
     "shell.execute_reply": "2024-04-26T11:56:52.230264Z"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "vOdbDq8xHj0F",
    "outputId": "355f8346-0e3c-4859-e825-becca10938a9",
    "papermill": {
     "duration": 1.135295,
     "end_time": "2024-04-26T11:56:52.232864",
     "exception": false,
     "start_time": "2024-04-26T11:56:51.097569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1276,     2,     4, ...,    13,   401,    26],\n",
       "       [    2,     4, 11580, ...,   401,    26,    22],\n",
       "       [    4, 11580,    10, ...,    26,    22,     9],\n",
       "       ...,\n",
       "       [   53,     4,    13, ...,    13, 35743,    99],\n",
       "       [    4,    13, 17441, ..., 35743,    99,  1452],\n",
       "       [   13, 17441,   176, ...,    99,  1452,   600]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2daa28",
   "metadata": {
    "id": "097phwQvHj0F",
    "papermill": {
     "duration": 0.020015,
     "end_time": "2024-04-26T11:56:52.273095",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.253080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create the LSTM Based Model\n",
    "Split the Data into Featureas and Labels\n",
    "\n",
    "X will be the first n words of sequence\n",
    "\n",
    "y will be the next word after the sequence\n",
    "\n",
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2b3ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.316451Z",
     "iopub.status.busy": "2024-04-26T11:56:52.316041Z",
     "iopub.status.idle": "2024-04-26T11:56:52.321210Z",
     "shell.execute_reply": "2024-04-26T11:56:52.320154Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "8kEuWAYBHj0F",
    "papermill": {
     "duration": 0.029524,
     "end_time": "2024-04-26T11:56:52.323479",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.293955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ce5da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.369749Z",
     "iopub.status.busy": "2024-04-26T11:56:52.369303Z",
     "iopub.status.idle": "2024-04-26T11:56:52.375075Z",
     "shell.execute_reply": "2024-04-26T11:56:52.373834Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "ObvN6tLZHj0G",
    "papermill": {
     "duration": 0.031136,
     "end_time": "2024-04-26T11:56:52.376929",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.345793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422348,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sequences[:,-1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934575d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.518908Z",
     "iopub.status.busy": "2024-04-26T11:56:52.518515Z",
     "iopub.status.idle": "2024-04-26T11:56:52.524802Z",
     "shell.execute_reply": "2024-04-26T11:56:52.523550Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "xEJ9WvPoHj0G",
    "papermill": {
     "duration": 0.032847,
     "end_time": "2024-04-26T11:56:52.527492",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.494645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_len = X.shape[1] #setting the seq_len to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d62a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.572234Z",
     "iopub.status.busy": "2024-04-26T11:56:52.571678Z",
     "iopub.status.idle": "2024-04-26T11:56:52.579351Z",
     "shell.execute_reply": "2024-04-26T11:56:52.578110Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "Saw0QjzbHj0G",
    "outputId": "8d26ee7e-c937-4c10-ec0b-57fa5778e51c",
    "papermill": {
     "duration": 0.033359,
     "end_time": "2024-04-26T11:56:52.582212",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.548853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422348, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape #ammount of sequences, each containing 50 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549ad38",
   "metadata": {
    "id": "Etw8aXF4Hj0G",
    "papermill": {
     "duration": 0.022799,
     "end_time": "2024-04-26T11:56:52.628329",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.605530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training the model\n",
    "LSTM layer to deal with the sequences, and Embedding layer to deal with the vocabulary\n",
    "\n",
    "Note: at the LSTM the defining number of neurons should be a multipe of the seq_len, tourned out a 2 worked out well and made calculations quite fast. took only over night...\n",
    "\n",
    "This part is a \"left over\" of the training to show the model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5242f4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.675097Z",
     "iopub.status.busy": "2024-04-26T11:56:52.674716Z",
     "iopub.status.idle": "2024-04-26T11:56:52.681496Z",
     "shell.execute_reply": "2024-04-26T11:56:52.680471Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713964674477,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "fdSSVg5_Hj0G",
    "papermill": {
     "duration": 0.033034,
     "end_time": "2024-04-26T11:56:52.683671",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.650637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(seq_len*2, return_sequences = True))\n",
    "    model.add(LSTM(seq_len*2))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63bfe83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:52.729908Z",
     "iopub.status.busy": "2024-04-26T11:56:52.729514Z",
     "iopub.status.idle": "2024-04-26T11:56:53.347958Z",
     "shell.execute_reply": "2024-04-26T11:56:53.346634Z"
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1713964675404,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "1sNzAr_AHj0G",
    "outputId": "ac408c2a-2e1d-406f-89d2-18a953b72baa",
    "papermill": {
     "duration": 0.644849,
     "end_time": "2024-04-26T11:56:53.350880",
     "exception": false,
     "start_time": "2024-04-26T11:56:52.706031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\miche\\Documents\\GitHub\\.venv\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:316: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 50)            1787200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50, 100)           60400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 35744)             3610144   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5548244 (21.16 MB)\n",
      "Trainable params: 5548244 (21.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4ea2a",
   "metadata": {
    "id": "xf9NRm7WHj0J",
    "papermill": {
     "duration": 0.023016,
     "end_time": "2024-04-26T11:57:05.138205",
     "exception": false,
     "start_time": "2024-04-26T11:57:05.115189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generating new Text based on Seed Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b54fe5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:05.185682Z",
     "iopub.status.busy": "2024-04-26T11:57:05.185299Z",
     "iopub.status.idle": "2024-04-26T11:57:05.193951Z",
     "shell.execute_reply": "2024-04-26T11:57:05.192539Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1713964833593,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "ReHyhkj2Hj0J",
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.034281,
     "end_time": "2024-04-26T11:57:05.195990",
     "exception": false,
     "start_time": "2024-04-26T11:57:05.161709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    this is the frist try of the generate text, without beam_search\n",
    "    it also gives the needed data for the generate_text_2 function\n",
    "    differnt possible returns!\n",
    "    \n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model, special case of num_gen_words == 1\n",
    "    '''\n",
    "\n",
    "    # Final Output\n",
    "    output_text = []\n",
    "\n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "\n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "\n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "\n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "\n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict(pad_encoded, verbose=0)[0]\n",
    "\n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[np.argmax(pred_word_ind)]\n",
    "\n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "\n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "\t\t# this part is for the generate_text_2 to return more data like probabilites\n",
    "        if num_gen_words == 1:\n",
    "            best_3_w = np.argsort(pred_word_ind)[-1:-4:-1]\n",
    "            return best_3_w, pred_word_ind[best_3_w], pred_word_ind\n",
    "\n",
    "\n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b76dda26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:05.243677Z",
     "iopub.status.busy": "2024-04-26T11:57:05.243306Z",
     "iopub.status.idle": "2024-04-26T11:57:05.255115Z",
     "shell.execute_reply": "2024-04-26T11:57:05.253854Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.038591,
     "end_time": "2024-04-26T11:57:05.257972",
     "exception": false,
     "start_time": "2024-04-26T11:57:05.219381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text_2(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    This is the good one, with beam_search\n",
    "    \n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "\n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Little Beam-search-like\n",
    "    beam_search = []\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "\n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "\n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "\n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Testing out grab best 3 words\n",
    "        best_3_w = np.argsort(pred_word_ind)[-1:-4:-1]\n",
    "        beam_search.append(best_3_w)\n",
    "        tokens_array = []\n",
    "        tokens_prob_array = []\n",
    "        for i in best_3_w:\n",
    "            # Grab word\n",
    "            pred_word = tokenizer.index_word[i]\n",
    "            \n",
    "            # Update the sequence of input text (shifting one over with the new word)\n",
    "            try_text = input_text + ' ' + pred_word\n",
    "            tokens, token_prop, _ = generate_text(model=model, tokenizer=tokenizer, seq_len=seq_len, seed_text=try_text, num_gen_words=1)\n",
    "            tokens_array.append(tokens)\n",
    "            tokens_prob_array.append(token_prop * pred_word_ind[i])\n",
    "        id_token = np.argmax(np.array(tokens_prob_array).reshape(9,))\n",
    "        ind_1st_word = id_token.__floordiv__(3)\n",
    "\n",
    "        ind_2nd_word = id_token - (3 * ind_1st_word)\n",
    "        counter = 0\n",
    "        while best_3_w[ind_1st_word] == tokens_array[ind_1st_word][ind_2nd_word]:\n",
    "            ind_1st_word = np.random.randint(0,3)\n",
    "            counter += 1\n",
    "            if counter > 4:\n",
    "                ind_2nd_word = np.random.randint(0,3) # if all fails, random pick, depending on the model, it should not happen\n",
    "        first_word = tokenizer.index_word[best_3_w[ind_1st_word]]\n",
    "        second_word = tokenizer.index_word[tokens_array[ind_1st_word][ind_2nd_word]]\n",
    "        \n",
    "        input_text += ' ' + first_word #+ \" \" + second_word    # as in the readme.md this didn't work out well\n",
    "\n",
    "        output_text.append(first_word)\n",
    "        # output_text.append(second_word)\n",
    "\n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe099312",
   "metadata": {},
   "source": [
    "### loading models\n",
    "Here we are loading unnesseary all models, its for convinience, so you can just run the block of the model's epoch you want to try out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44705930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:53.395985Z",
     "iopub.status.busy": "2024-04-26T11:56:53.395451Z",
     "iopub.status.idle": "2024-04-26T11:56:55.795154Z",
     "shell.execute_reply": "2024-04-26T11:56:55.793539Z"
    },
    "papermill": {
     "duration": 2.425723,
     "end_time": "2024-04-26T11:56:55.798072",
     "exception": false,
     "start_time": "2024-04-26T11:56:53.372349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5\n",
    "model = keras.saving.load_model(BASE_DIR + '/model/alfa_dl_model05-0.14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c65533a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:55.849146Z",
     "iopub.status.busy": "2024-04-26T11:56:55.848697Z",
     "iopub.status.idle": "2024-04-26T11:56:58.124245Z",
     "shell.execute_reply": "2024-04-26T11:56:58.122618Z"
    },
    "papermill": {
     "duration": 2.304673,
     "end_time": "2024-04-26T11:56:58.127059",
     "exception": false,
     "start_time": "2024-04-26T11:56:55.822386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 21\n",
    "model = keras.saving.load_model(BASE_DIR + '/model/alfa_dl_model10-0.21.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26cc83f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:56:58.173133Z",
     "iopub.status.busy": "2024-04-26T11:56:58.172765Z",
     "iopub.status.idle": "2024-04-26T11:57:00.433612Z",
     "shell.execute_reply": "2024-04-26T11:57:00.432049Z"
    },
    "papermill": {
     "duration": 2.286239,
     "end_time": "2024-04-26T11:57:00.436033",
     "exception": false,
     "start_time": "2024-04-26T11:56:58.149794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 31\n",
    "model = keras.saving.load_model(BASE_DIR + '/model/alfa_dl_model31-0.45.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a53209e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:00.485682Z",
     "iopub.status.busy": "2024-04-26T11:57:00.485324Z",
     "iopub.status.idle": "2024-04-26T11:57:02.808692Z",
     "shell.execute_reply": "2024-04-26T11:57:02.807537Z"
    },
    "papermill": {
     "duration": 2.352053,
     "end_time": "2024-04-26T11:57:02.811698",
     "exception": false,
     "start_time": "2024-04-26T11:57:00.459645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 41\n",
    "model = keras.saving.load_model(BASE_DIR + '/model/alfa_dl_model41-0.52.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caa00fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:02.861037Z",
     "iopub.status.busy": "2024-04-26T11:57:02.860656Z",
     "iopub.status.idle": "2024-04-26T11:57:05.089753Z",
     "shell.execute_reply": "2024-04-26T11:57:05.088168Z"
    },
    "papermill": {
     "duration": 2.257004,
     "end_time": "2024-04-26T11:57:05.092702",
     "exception": false,
     "start_time": "2024-04-26T11:57:02.835698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 50\n",
    "model = keras.saving.load_model(BASE_DIR + '/model/alfa_dl_model50-0.55.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cca935",
   "metadata": {},
   "source": [
    "# Run all blocks below again and enjoy the results\n",
    "the generate_text without beam_search most times fails even at 25 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "835def23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:05.308092Z",
     "iopub.status.busy": "2024-04-26T11:57:05.307713Z",
     "iopub.status.idle": "2024-04-26T11:57:05.315997Z",
     "shell.execute_reply": "2024-04-26T11:57:05.314713Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1713964833593,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "NJupV9kWHj0K",
    "papermill": {
     "duration": 0.035877,
     "end_time": "2024-04-26T11:57:05.318245",
     "exception": false,
     "start_time": "2024-04-26T11:57:05.282368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z. B. durch andere Personen , die bei der Messung zugegen sind oder die Messperson während der Ablesung des Messergebnisses , ca. 27 Feldstärkemes sung , ohne Wiederholbarkeit ca. 40 , einschließlich Wiederholbarkeit treten unregelmäßig auf und resultieren in unvorhersehbaren Schwankungen in Größe und Vorzeichen , entstehen durch nicht zu beeinflussende'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#random.seed(112) \n",
    "ramdom_pick = random.randint(0,len(text_sequences))\n",
    "random_seed_text = text_sequences[ramdom_pick]\n",
    "seed_text = ' '.join(random_seed_text)\n",
    "seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4231b7",
   "metadata": {},
   "source": [
    "if you now go back up and only run 1 block of the models, you can try out the different epochs, and see how it evolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eea54d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:05.365119Z",
     "iopub.status.busy": "2024-04-26T11:57:05.364770Z",
     "iopub.status.idle": "2024-04-26T11:57:32.933590Z",
     "shell.execute_reply": "2024-04-26T11:57:32.932558Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1713964833593,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "jYMXeagYHj0K",
    "papermill": {
     "duration": 27.594401,
     "end_time": "2024-04-26T11:57:32.935428",
     "exception": false,
     "start_time": "2024-04-26T11:57:05.341027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsystematische änderungen der messbedingungen z. untergruppen oder befähigungsnachweis zum elektrofahrzeug v emkg der gleichung rundfunk den messebenen 1 , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_2(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c451ec1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:32.982214Z",
     "iopub.status.busy": "2024-04-26T11:57:32.981826Z",
     "iopub.status.idle": "2024-04-26T11:57:34.906015Z",
     "shell.execute_reply": "2024-04-26T11:57:34.904467Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1713964833593,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "VMzN82anHj0K",
    "papermill": {
     "duration": 1.950456,
     "end_time": "2024-04-26T11:57:34.908389",
     "exception": false,
     "start_time": "2024-04-26T11:57:32.957933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsystematische änderungen der messbedingungen z. untergruppen , , , , , , , , , , , , , , , , , , ,'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c0dd7c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:34.958152Z",
     "iopub.status.busy": "2024-04-26T11:57:34.957794Z",
     "iopub.status.idle": "2024-04-26T11:57:35.046175Z",
     "shell.execute_reply": "2024-04-26T11:57:35.044664Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1713964833593,
     "user": {
      "displayName": "Jimmy Knox",
      "userId": "00773664586105526662"
     },
     "user_tz": -120
    },
    "id": "VMzN82anHj0K",
    "papermill": {
     "duration": 0.117325,
     "end_time": "2024-04-26T11:57:35.049079",
     "exception": false,
     "start_time": "2024-04-26T11:57:34.931754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=1) # used for looking up some numbbers\n",
    "# 1st array are the token, 2nd their probabilities, 3rd all probabilities of all tokens in order of the vocab_size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ff5804b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T11:57:35.098907Z",
     "iopub.status.busy": "2024-04-26T11:57:35.098501Z",
     "iopub.status.idle": "2024-04-26T11:57:35.211559Z",
     "shell.execute_reply": "2024-04-26T11:57:35.210368Z"
    },
    "papermill": {
     "duration": 0.140835,
     "end_time": "2024-04-26T11:57:35.214234",
     "exception": false,
     "start_time": "2024-04-26T11:57:35.073399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# used for some testing, to figure out how certain the AI is when certain hickups appeared\n",
    "# NOTE: there is a import down here\n",
    "\n",
    "# _, __, array = generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=1)\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(array)\n",
    "# df.describe()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4883601,
     "sourceId": 8234179,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 31474,
     "sourceId": 39601,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.047435,
   "end_time": "2024-04-26T11:57:38.548266",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-26T11:55:37.500831",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
